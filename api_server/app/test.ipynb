{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import glob\n",
    "import ir_datasets\n",
    "if not pt.started():\n",
    "  pt.init()\n",
    "\n",
    "from pyterrier_t5 import MonoT5ReRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nyt = ir_datasets.load(\"nyt\")\n",
    "dataset_wapo = ir_datasets.load(\"wapo/v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ref_nyt = pt.IndexRef.of(\"/app/indices/nyt/\")\n",
    "index_ref_wapo = pt.IndexRef.of(\"/app/indices/wapo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:217: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "monoT5 = MonoT5ReRanker(text_field=\"body\", batch_size=100, verbose=True)\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index_ref_wapo , wmodel='BM25', num_results=200)\n",
    "mono_pipeline = bm25 >> pt.text.get_text(index_ref_wapo, \"body\") >> monoT5\n",
    "\n",
    "mono_pipeline_500 = pt.BatchRetrieve(index_ref_wapo , wmodel='BM25', num_results=500) >>  pt.text.get_text(index_ref_wapo, \"body\") >> monoT5\n",
    "mono_pipeline_50 = pt.BatchRetrieve(index_ref_wapo , wmodel='BM25', num_results=50) >>  pt.text.get_text(index_ref_wapo, \"body\") >> monoT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1_nyt = pt.get_dataset('irds:nyt/trec-core-2017')\n",
    "ds1_wapo = pt.get_dataset('irds:wapo/v2/trec-core-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>1001536</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307</td>\n",
       "      <td>1002887</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>307</td>\n",
       "      <td>1005682</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>1007340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>101295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30025</th>\n",
       "      <td>690</td>\n",
       "      <td>991749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30026</th>\n",
       "      <td>690</td>\n",
       "      <td>993504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30027</th>\n",
       "      <td>690</td>\n",
       "      <td>994345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30028</th>\n",
       "      <td>690</td>\n",
       "      <td>995425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30029</th>\n",
       "      <td>690</td>\n",
       "      <td>996059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30030 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid    docno  label iteration\n",
       "0      307  1001536      1         0\n",
       "1      307  1002887      1         0\n",
       "2      307  1005682      0         0\n",
       "3      307  1007340      1         0\n",
       "4      307   101295      1         0\n",
       "...    ...      ...    ...       ...\n",
       "30025  690   991749      0         0\n",
       "30026  690   993504      0         0\n",
       "30027  690   994345      0         0\n",
       "30028  690   995425      0         0\n",
       "30029  690   996059      0         0\n",
       "\n",
       "[30030 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1_nyt.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] https://trec.nist.gov/data/core/core_nist.txt\n",
      "[INFO] [finished] https://trec.nist.gov/data/core/core_nist.txt: [00:00] [24.4kB] [229kB/s]\n",
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "for i, row in ds1_nyt.get_topics('title').iterrows():\n",
    "    query = row['query']\n",
    "\n",
    "    with open(f\"/workspace/data/nyt/topics/topic.{i+1}\", \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('title', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    }
   ],
   "source": [
    "nyt_topics = ds1_nyt.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_topics.to_pickle(\"nyt_topics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('title', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    }
   ],
   "source": [
    "ds1_wapo.get_topics().to_pickle(\"wapo_topics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nyt_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds1_nyt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/app/test.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f737569725f73696d756c6174696f6e5f31227d/app/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ds1_nyt\u001b[39m.\u001b[39mget_topics()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds1_nyt' is not defined"
     ]
    }
   ],
   "source": [
    "ds1_nyt.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_queries = \"\"\n",
    "for i, row in ds1_nyt.get_topics('title').iterrows():\n",
    "    i_id = i+1\n",
    "    query = row['query']\n",
    "\n",
    "    line = f\"1,1,{row['qid']},{query}\\n\"\n",
    "    title_queries += line\n",
    "\n",
    "with open(f\"/workspace/data/nyt/title_queries\", \"w\") as f:\n",
    "    f.write(title_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('title', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    }
   ],
   "source": [
    "full_topics = \"\"\n",
    "for i, row in ds1_nyt.get_topics().iterrows():\n",
    "    title = row['title']\n",
    "    description = row['description']\n",
    "    narrative = row['narrative']\n",
    "\n",
    "    line = f\"1,1,{row['qid']},{title},{description},{narrative}\\n\"\n",
    "    full_topics += line\n",
    "\n",
    "with open(f\"/workspace/data/nyt/full_topics\", \"w\") as f:\n",
    "    f.write(full_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qrels\n",
    "wapo_qrel_path = \"/workspace/data/wapo/wapo_qrels1\"\n",
    "qrels = \"\"\n",
    "for i, row in ds1_wapo.get_qrels().iterrows():\n",
    "    label = 1 if int(row['label']) > 0 else 0\n",
    "    line = f\"{row['qid']} 0 {row['docno']} {label}\\n\"\n",
    "    qrels+= line\n",
    "\n",
    "with open(wapo_qrel_path, \"w\") as f:\n",
    "    f.write(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] https://trec.nist.gov/data/core/topics2018.txt\n",
      "[INFO] [finished] https://trec.nist.gov/data/core/topics2018.txt: [00:00] [24.1kB] [59.9MB/s]\n",
      "[INFO] [starting] https://trec.nist.gov/data/core/qrels2018.txt            \n",
      "[INFO] [finished] https://trec.nist.gov/data/core/qrels2018.txt: [00:00] [1.12MB] [1.28MB/s]\n",
      "pt.Experiment: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.95s/system]          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_10</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.168733</td>\n",
       "      <td>0.663436</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.37107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name       map  recip_rank   P_10  ndcg_cut_10\n",
       "0  BM25  0.168733    0.663436  0.404      0.37107"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    ds1_wapo.get_topics('title'),\n",
    "    ds1_wapo.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"recip_rank\", \"P_10\", \"ndcg_cut_10\"],\n",
    "    names=[\"BM25\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monoT5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:29<00:00,  2.10s/batches]\n",
      "pt.Experiment: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.32s/system]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_10</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MonoT5</td>\n",
       "      <td>0.20841</td>\n",
       "      <td>0.670647</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.446702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name      map  recip_rank   P_10  ndcg_cut_10\n",
       "0  MonoT5  0.20841    0.670647  0.476     0.446702"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [mono_pipeline],\n",
    "    ds1_wapo.get_topics('title'),\n",
    "    ds1_wapo.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"recip_rank\", \"P_10\", \"ndcg_cut_10\"],\n",
    "    names=[\"MonoT5\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.Experiment(\n",
    "    [mono_pipeline_500],\n",
    "    ds1_wapo.get_topics('title'),\n",
    "    ds1_wapo.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"recip_rank\", \"P_10\", \"ndcg_cut_10\"],\n",
    "    names=[\"MonoT5\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>563223</td>\n",
       "      <td>f233ecdeb87a44a6aa9ac429999d2d4c</td>\n",
       "      <td>0</td>\n",
       "      <td>19.370159</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>486152</td>\n",
       "      <td>4a7c2970fd9bf65fe09c7cf46df7b06d</td>\n",
       "      <td>1</td>\n",
       "      <td>18.690675</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>486153</td>\n",
       "      <td>9171debc316e5e2782e0d2404ca7d09d</td>\n",
       "      <td>2</td>\n",
       "      <td>18.690675</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>352722</td>\n",
       "      <td>34d443eec1add515a2fbc4af2c8a3a57</td>\n",
       "      <td>3</td>\n",
       "      <td>18.372576</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>546574</td>\n",
       "      <td>f1ab493726e1e6f5dd90615d5a1b58b8</td>\n",
       "      <td>4</td>\n",
       "      <td>18.340060</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>351935</td>\n",
       "      <td>a64ab05765cb2b25a6f18c03b20f5a3a</td>\n",
       "      <td>195</td>\n",
       "      <td>13.074723</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>351936</td>\n",
       "      <td>8d0f44ec22604cd5c08d74fc8ffa7cf4</td>\n",
       "      <td>196</td>\n",
       "      <td>13.074723</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>351954</td>\n",
       "      <td>56b94f8fd53b63608931a373f813b7b1</td>\n",
       "      <td>197</td>\n",
       "      <td>13.074421</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>305768</td>\n",
       "      <td>583e232f566fe972d5d1c1e5652bbb75</td>\n",
       "      <td>198</td>\n",
       "      <td>13.058146</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>22535</td>\n",
       "      <td>0faed48e-c914-11e1-8d21-45ee617a712a</td>\n",
       "      <td>199</td>\n",
       "      <td>13.049378</td>\n",
       "      <td>women in parliament</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid   docid                                 docno  rank      score  \\\n",
       "0     1  563223      f233ecdeb87a44a6aa9ac429999d2d4c     0  19.370159   \n",
       "1     1  486152      4a7c2970fd9bf65fe09c7cf46df7b06d     1  18.690675   \n",
       "2     1  486153      9171debc316e5e2782e0d2404ca7d09d     2  18.690675   \n",
       "3     1  352722      34d443eec1add515a2fbc4af2c8a3a57     3  18.372576   \n",
       "4     1  546574      f1ab493726e1e6f5dd90615d5a1b58b8     4  18.340060   \n",
       "..   ..     ...                                   ...   ...        ...   \n",
       "195   1  351935      a64ab05765cb2b25a6f18c03b20f5a3a   195  13.074723   \n",
       "196   1  351936      8d0f44ec22604cd5c08d74fc8ffa7cf4   196  13.074723   \n",
       "197   1  351954      56b94f8fd53b63608931a373f813b7b1   197  13.074421   \n",
       "198   1  305768      583e232f566fe972d5d1c1e5652bbb75   198  13.058146   \n",
       "199   1   22535  0faed48e-c914-11e1-8d21-45ee617a712a   199  13.049378   \n",
       "\n",
       "                   query  \n",
       "0    women in parliament  \n",
       "1    women in parliament  \n",
       "2    women in parliament  \n",
       "3    women in parliament  \n",
       "4    women in parliament  \n",
       "..                   ...  \n",
       "195  women in parliament  \n",
       "196  women in parliament  \n",
       "197  women in parliament  \n",
       "198  women in parliament  \n",
       "199  women in parliament  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25.search(\"women in parliament\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monoT5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/batches]\n"
     ]
    }
   ],
   "source": [
    "res = mono_pipeline_50.search(\"women in parliament\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.Experiment(\n",
    "    [mono_pipeline_50\n",
    "    ],\n",
    "    ds1_wapo.get_topics('title')[:2],\n",
    "    ds1_wapo.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"recip_rank\", \"P_10\", \"ndcg_cut_10\"],\n",
    "    names=[\"MonoT5\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_path = f\"workspace/data/wapo/wapo_topics.pkl\"\n",
    "topics = pickle.load(open(topic_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate list of low signal terms from desription/narrative\n",
    "\n",
    "all_terms = []\n",
    "\n",
    "for i, row in topics.iterrows():\n",
    "    all_terms += row['description'].split(\" \")\n",
    "    all_terms += row['narrative'].split(\" \")\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cnt_list = Counter(all_terms)\n",
    "cnt_list = {k:v for k, v in sorted(cnt_list.items(), key=lambda item: -item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 149,\n",
       " 'of': 107,\n",
       " 'to': 64,\n",
       " 'that': 57,\n",
       " 'in': 56,\n",
       " 'or': 56,\n",
       " 'are': 50,\n",
       " 'documents': 45,\n",
       " 'and': 45,\n",
       " 'a': 40,\n",
       " 'for': 34,\n",
       " 'relevant.': 33,\n",
       " 'not': 29,\n",
       " 'on': 27,\n",
       " 'relevant': 25,\n",
       " 'Relevant': 22,\n",
       " 'A': 21,\n",
       " 'Find': 21,\n",
       " 'is': 20,\n",
       " 'discuss': 20,\n",
       " 'document': 20,\n",
       " 'be': 19,\n",
       " 'as': 19,\n",
       " 'by': 18,\n",
       " 'have': 17,\n",
       " 'describe': 17,\n",
       " 'will': 15,\n",
       " 'Documents': 14,\n",
       " 'any': 12,\n",
       " 'from': 12,\n",
       " 'U.S.': 12,\n",
       " 'What': 12,\n",
       " 'an': 11,\n",
       " 'include': 10,\n",
       " 'countries': 9,\n",
       " 'would': 9,\n",
       " 'other': 9,\n",
       " 'Identify': 9,\n",
       " 'specific': 9,\n",
       " 'their': 8,\n",
       " 'also': 8,\n",
       " 'efforts': 8,\n",
       " 'The': 8,\n",
       " 'being': 8,\n",
       " '': 8,\n",
       " 'which': 7,\n",
       " 'been': 7,\n",
       " 'taken': 7,\n",
       " 'contain': 7,\n",
       " 'about': 7,\n",
       " 'mention': 7,\n",
       " 'such': 7,\n",
       " 'use': 7,\n",
       " 'must': 7,\n",
       " 'either': 7,\n",
       " 'between': 6,\n",
       " 'there': 6,\n",
       " 'food': 6,\n",
       " 'steps': 6,\n",
       " 'increase': 6,\n",
       " 'with': 6,\n",
       " 'human': 6,\n",
       " 'people': 6,\n",
       " 'can': 6,\n",
       " 'relevant,': 6,\n",
       " 'treatment': 6,\n",
       " 'identify': 6,\n",
       " 'women': 5,\n",
       " 'has': 5,\n",
       " 'prevent': 5,\n",
       " 'species': 5,\n",
       " 'information': 5,\n",
       " 'may': 5,\n",
       " 'cause': 5,\n",
       " 'reasons': 5,\n",
       " 'some': 5,\n",
       " 'group': 5,\n",
       " 'technology': 5,\n",
       " 'Washington': 5,\n",
       " 'Post': 5,\n",
       " 'black': 4,\n",
       " 'scientific': 4,\n",
       " 'new': 4,\n",
       " 'and/or': 4,\n",
       " 'all': 4,\n",
       " 'reports': 4,\n",
       " 'what': 4,\n",
       " 'screening': 4,\n",
       " 'measures': 4,\n",
       " 'specify': 4,\n",
       " 'individuals': 4,\n",
       " 'computer': 4,\n",
       " 'support': 4,\n",
       " 'damage': 4,\n",
       " 'Cuba': 4,\n",
       " 'programs': 4,\n",
       " 'where': 4,\n",
       " 'polio': 4,\n",
       " 'impact': 4,\n",
       " 'descriptions': 4,\n",
       " 'reactions': 4,\n",
       " 'President': 4,\n",
       " 'his': 4,\n",
       " 'chemical': 4,\n",
       " 'age': 4,\n",
       " 'infections': 4,\n",
       " 'political': 3,\n",
       " 'representation': 3,\n",
       " 'percentage': 3,\n",
       " 'if': 3,\n",
       " 'those': 3,\n",
       " 'worldwide': 3,\n",
       " 'causes': 3,\n",
       " 'humans.': 3,\n",
       " 'well': 3,\n",
       " 'better': 3,\n",
       " 'luggage': 3,\n",
       " 'but': 3,\n",
       " 'particular': 3,\n",
       " 'using': 3,\n",
       " 'Is': 3,\n",
       " 'it': 3,\n",
       " 'health': 3,\n",
       " 'tunnels': 3,\n",
       " 'used': 3,\n",
       " 'tunnel': 3,\n",
       " 'discussing': 3,\n",
       " 'unless': 3,\n",
       " 'hydrogen': 3,\n",
       " 'fuel': 3,\n",
       " 'its': 3,\n",
       " 'description': 3,\n",
       " 'tropical': 3,\n",
       " 'rain': 3,\n",
       " 'caused': 3,\n",
       " 'they': 3,\n",
       " 'dogs': 3,\n",
       " 'law': 3,\n",
       " 'result': 3,\n",
       " 'exposure': 3,\n",
       " 'others': 3,\n",
       " 'statements': 3,\n",
       " 'clergy': 3,\n",
       " 'stampedes': 3,\n",
       " 'more': 3,\n",
       " 'religious': 3,\n",
       " 'objections': 3,\n",
       " 'vaccination': 3,\n",
       " 'had': 3,\n",
       " 'ban': 3,\n",
       " 'middle': 3,\n",
       " 'class': 3,\n",
       " 'invasive': 3,\n",
       " 'controlling': 3,\n",
       " 'link': 3,\n",
       " 'plans': 3,\n",
       " 'social': 3,\n",
       " 'marijuana': 3,\n",
       " 'responsible': 3,\n",
       " 'discussion': 3,\n",
       " 'released': 3,\n",
       " 'eggs': 3,\n",
       " 'population': 3,\n",
       " 'Pertinent': 2,\n",
       " 'power': 2,\n",
       " 'particularly': 2,\n",
       " 'relating': 2,\n",
       " 'this': 2,\n",
       " 'lack': 2,\n",
       " 'women,': 2,\n",
       " 'certain': 2,\n",
       " 'legislatures,': 2,\n",
       " 'female': 2,\n",
       " 'vicious': 2,\n",
       " 'attacks': 2,\n",
       " 'possible': 2,\n",
       " 'them': 2,\n",
       " 'methods': 2,\n",
       " 'wildlife': 2,\n",
       " 'control': 2,\n",
       " 'scrutinize': 2,\n",
       " 'passengers': 2,\n",
       " 'international': 2,\n",
       " 'airports': 2,\n",
       " 'carry-on': 2,\n",
       " 'increased': 2,\n",
       " 'security': 2,\n",
       " 'additional': 2,\n",
       " 'does': 2,\n",
       " 'body': 2,\n",
       " 'species.': 2,\n",
       " 'daily': 2,\n",
       " 'physical': 2,\n",
       " 'how': 2,\n",
       " 'these': 2,\n",
       " 'problems': 2,\n",
       " 'incidents': 2,\n",
       " 'while': 2,\n",
       " 'disasters': 2,\n",
       " 'etc.': 2,\n",
       " 'occurring': 2,\n",
       " 'during': 2,\n",
       " 'lives': 2,\n",
       " 'taking': 2,\n",
       " 'fishing': 2,\n",
       " 'one': 2,\n",
       " 'research': 2,\n",
       " 'opposition': 2,\n",
       " 'who': 2,\n",
       " 'use.': 2,\n",
       " 'mercy': 2,\n",
       " 'All': 2,\n",
       " 'cases': 2,\n",
       " 'life': 2,\n",
       " 'systems': 2,\n",
       " 'general': 2,\n",
       " 'case': 2,\n",
       " 'automobile': 2,\n",
       " 'recalls': 2,\n",
       " 'car': 2,\n",
       " 'preserve': 2,\n",
       " 'Amazon': 2,\n",
       " 'forest;': 2,\n",
       " 'loss': 2,\n",
       " 'area': 2,\n",
       " 'How': 2,\n",
       " 'sugar': 2,\n",
       " 'stolen': 2,\n",
       " 'forged': 2,\n",
       " 'art': 2,\n",
       " 'media': 2,\n",
       " 'mass-produced': 2,\n",
       " 'even': 2,\n",
       " 'though': 2,\n",
       " 'education': 2,\n",
       " 'help': 2,\n",
       " 'Greek': 2,\n",
       " 'philosophy': 2,\n",
       " 'references': 2,\n",
       " 'productions': 2,\n",
       " 'discoveries': 2,\n",
       " 'indicate': 2,\n",
       " 'heroic': 2,\n",
       " 'acts': 2,\n",
       " 'groups': 2,\n",
       " 'considering': 2,\n",
       " 'To': 2,\n",
       " 'country': 2,\n",
       " 'church': 2,\n",
       " '20': 2,\n",
       " 'stamp': 2,\n",
       " 'eligible': 2,\n",
       " 'advantage': 2,\n",
       " 'Saudi': 2,\n",
       " 'Arabia': 2,\n",
       " 'giving': 2,\n",
       " 'decline': 2,\n",
       " 'U.S.,': 2,\n",
       " 'direct': 2,\n",
       " '\"Women': 2,\n",
       " '20s\"': 2,\n",
       " 'campaign': 2,\n",
       " 'Andrew': 2,\n",
       " 'Jackson': 2,\n",
       " '$20': 2,\n",
       " 'bill.': 2,\n",
       " 'Harriet': 2,\n",
       " 'Tubman': 2,\n",
       " 'eating': 2,\n",
       " 'improve': 2,\n",
       " 'paralyzed': 2,\n",
       " 'ways': 2,\n",
       " 'Use': 2,\n",
       " 'exoskeletons': 2,\n",
       " 'medical': 2,\n",
       " 'Venezuelan': 2,\n",
       " 'Chavez': 2,\n",
       " 'received': 2,\n",
       " 'Cuba.': 2,\n",
       " 'verdict': 2,\n",
       " 'reached': 2,\n",
       " 'trial': 2,\n",
       " 'Boston': 2,\n",
       " 'marathon': 2,\n",
       " 'bombing': 2,\n",
       " 'explicitly': 2,\n",
       " 'suspects': 2,\n",
       " 'protect': 2,\n",
       " 'asteroid': 2,\n",
       " 'toxic': 2,\n",
       " 'cars': 2,\n",
       " 'full': 2,\n",
       " 'account': 2,\n",
       " 'bullying': 2,\n",
       " 'now': 2,\n",
       " 'compared': 2,\n",
       " 'ago.': 2,\n",
       " \"China's\": 2,\n",
       " 'one-child': 2,\n",
       " 'journalist': 2,\n",
       " 'Jason': 2,\n",
       " 'Rezaian': 2,\n",
       " 'Iranian': 2,\n",
       " 'prison.': 2,\n",
       " 'was': 2,\n",
       " 'him': 2,\n",
       " 'actions': 2,\n",
       " 'Congress': 2,\n",
       " 'federal': 2,\n",
       " 'minimum': 2,\n",
       " 'details': 2,\n",
       " 'prisoner': 2,\n",
       " 'exchange': 2,\n",
       " 'USAID': 2,\n",
       " 'contractor': 2,\n",
       " 'Alan': 2,\n",
       " 'actual': 2,\n",
       " 'healthy': 2,\n",
       " 'contains': 2,\n",
       " 'workforce.': 2,\n",
       " 'mortality': 2,\n",
       " 'bacterial': 2,\n",
       " 'bacteria': 2,\n",
       " 'email': 2,\n",
       " 'cyberattack': 2,\n",
       " 'Sony': 2,\n",
       " 'Pictures.': 2,\n",
       " 'means': 2,\n",
       " 'spread': 2,\n",
       " 'methicillin-resistant': 2,\n",
       " 'Staph': 2,\n",
       " 'Aureus': 2,\n",
       " '(MRSA)': 2,\n",
       " 'describing': 2,\n",
       " 'both': 2,\n",
       " 'purchase': 2,\n",
       " 'Jeff': 2,\n",
       " 'Bezos': 2,\n",
       " 'news': 2,\n",
       " 'corn': 2,\n",
       " 'ethanol': 2,\n",
       " 'reflect': 1,\n",
       " 'fact': 1,\n",
       " 'continue': 1,\n",
       " 'poorly': 1,\n",
       " 'represented': 1,\n",
       " 'parliaments': 1,\n",
       " 'across': 1,\n",
       " 'world,': 1,\n",
       " 'gap': 1,\n",
       " 'sexes': 1,\n",
       " 'very': 1,\n",
       " 'wide,': 1,\n",
       " 'Third': 1,\n",
       " 'World.': 1,\n",
       " 'issue': 1,\n",
       " 'mandate': 1,\n",
       " 'inclusion': 1,\n",
       " 'decreases': 1,\n",
       " 'no': 1,\n",
       " 'women.': 1,\n",
       " 'frequency': 1,\n",
       " 'bear': 1,\n",
       " 'savage': 1,\n",
       " 'behavior.': 1,\n",
       " 'It': 1,\n",
       " 'reported': 1,\n",
       " 'cosmetics': 1,\n",
       " 'sometimes': 1,\n",
       " 'attract': 1,\n",
       " 'hungry': 1,\n",
       " 'bears,': 1,\n",
       " 'causing': 1,\n",
       " 'viciously': 1,\n",
       " 'attack': 1,\n",
       " 'aforementioned': 1,\n",
       " 'speculation': 1,\n",
       " 'preferably': 1,\n",
       " 'community': 1,\n",
       " 'bears.': 1,\n",
       " 'detail': 1,\n",
       " 'devised': 1,\n",
       " 'officials': 1,\n",
       " 'modify': 1,\n",
       " 'savageness': 1,\n",
       " 'bear.': 1,\n",
       " 'effectiveness': 1,\n",
       " 'flights,': 1,\n",
       " 'flights.': 1,\n",
       " 'domestic': 1,\n",
       " 'flights': 1,\n",
       " 'step': 1,\n",
       " 'up': 1,\n",
       " 'baggage.': 1,\n",
       " 'With': 1,\n",
       " 'concerns': 1,\n",
       " 'terrorism,': 1,\n",
       " 'articles': 1,\n",
       " 'airport': 1,\n",
       " 'flight': 1,\n",
       " 'safety': 1,\n",
       " 'mere': 1,\n",
       " 'enhanced': 1,\n",
       " 'constitute': 1,\n",
       " 'relevance.': 1,\n",
       " 'Additional': 1,\n",
       " 'refer': 1,\n",
       " 'something': 1,\n",
       " 'beyond': 1,\n",
       " 'just': 1,\n",
       " 'passenger': 1,\n",
       " 'normal': 1,\n",
       " 'methods.': 1,\n",
       " 'Examples': 1,\n",
       " 'personnel,': 1,\n",
       " 'automated': 1,\n",
       " 'processes,': 1,\n",
       " 'sophisticated': 1,\n",
       " 'monitoring': 1,\n",
       " 'devices,': 1,\n",
       " 'whole': 1,\n",
       " 'imaging': 1,\n",
       " 'techniques,': 1,\n",
       " 'extraordinary': 1,\n",
       " 'screen': 1,\n",
       " 'baggage': 1,\n",
       " 'compartment.': 1,\n",
       " 'spotted': 1,\n",
       " 'owl': 1,\n",
       " 'episode': 1,\n",
       " 'America': 1,\n",
       " 'highlighted': 1,\n",
       " 'extinction': 1,\n",
       " 'known': 1,\n",
       " 'effort': 1,\n",
       " 'demise': 1,\n",
       " 'native': 1,\n",
       " 'countries.': 1,\n",
       " 'begun': 1,\n",
       " 'declines?': 1,\n",
       " 'item': 1,\n",
       " 'country,': 1,\n",
       " 'involved': 1,\n",
       " 'species,': 1,\n",
       " 'save': 1,\n",
       " 'hazardous': 1,\n",
       " 'work': 1,\n",
       " 'terminals': 1,\n",
       " 'basis?': 1,\n",
       " 'expands': 1,\n",
       " 'disorder/problems': 1,\n",
       " 'associated': 1,\n",
       " 'working': 1,\n",
       " 'terminals.': 1,\n",
       " 'Such': 1,\n",
       " 'things': 1,\n",
       " 'carpel': 1,\n",
       " 'tunnel,': 1,\n",
       " 'cataracts,': 1,\n",
       " 'fatigue': 1,\n",
       " 'said': 1,\n",
       " 'associated,': 1,\n",
       " 'widespread': 1,\n",
       " 'done': 1,\n",
       " 'alleviate': 1,\n",
       " 'problems.': 1,\n",
       " 'smuggling.': 1,\n",
       " 'shows': 1,\n",
       " 'incident': 1,\n",
       " 'humans': 1,\n",
       " '(at': 1,\n",
       " 'least': 1,\n",
       " 'ten)': 1,\n",
       " 'smuggled.': 1,\n",
       " 'smugglers': 1,\n",
       " 'realize': 1,\n",
       " 'monetary': 1,\n",
       " 'gain': 1,\n",
       " 'actions,': 1,\n",
       " 'smuggled': 1,\n",
       " 'willing': 1,\n",
       " 'participants.': 1,\n",
       " 'occurred': 1,\n",
       " 'transportation?': 1,\n",
       " 'identifies': 1,\n",
       " 'disaster': 1,\n",
       " 'trains,': 1,\n",
       " 'motor': 1,\n",
       " 'vehicles,': 1,\n",
       " 'people.': 1,\n",
       " 'Wind': 1,\n",
       " 'wiring,': 1,\n",
       " 'sewage,': 1,\n",
       " 'water,': 1,\n",
       " 'oil,': 1,\n",
       " 'problem': 1,\n",
       " 'fire,': 1,\n",
       " 'earthquake,': 1,\n",
       " 'flood,': 1,\n",
       " 'explosion': 1,\n",
       " 'accidental': 1,\n",
       " 'planned.': 1,\n",
       " 'construction': 1,\n",
       " 'were': 1,\n",
       " 'threatened.': 1,\n",
       " 'modern': 1,\n",
       " 'instances': 1,\n",
       " 'old': 1,\n",
       " 'fashioned': 1,\n",
       " 'piracy,': 1,\n",
       " 'boarding': 1,\n",
       " 'boats?': 1,\n",
       " 'piracy': 1,\n",
       " 'water': 1,\n",
       " 'legal': 1,\n",
       " 'ships': 1,\n",
       " 'contents': 1,\n",
       " 'national': 1,\n",
       " 'authority': 1,\n",
       " 'non-relevant.': 1,\n",
       " 'Clashes': 1,\n",
       " 'vessels': 1,\n",
       " 'over': 1,\n",
       " 'vessel': 1,\n",
       " 'boarded.': 1,\n",
       " 'status': 1,\n",
       " 'feasible': 1,\n",
       " 'energy': 1,\n",
       " 'source?': 1,\n",
       " 'progress': 1,\n",
       " 'controlled': 1,\n",
       " 'fusion': 1,\n",
       " 'engines.': 1,\n",
       " 'euro,': 1,\n",
       " 'European': 1,\n",
       " 'currency.': 1,\n",
       " 'should': 1,\n",
       " 'oppose': 1,\n",
       " 'euro': 1,\n",
       " 'reason(s)': 1,\n",
       " 'killings.': 1,\n",
       " 'individual': 1,\n",
       " 'killing': 1,\n",
       " 'except': 1,\n",
       " '\"letters': 1,\n",
       " 'editor\"': 1,\n",
       " 'mentioning': 1,\n",
       " 'removal': 1,\n",
       " 'without': 1,\n",
       " 'specifics,': 1,\n",
       " \"victim's\": 1,\n",
       " 'name': 1,\n",
       " 'Cases': 1,\n",
       " 'determined': 1,\n",
       " 'murder-suicide': 1,\n",
       " 'recalls.': 1,\n",
       " 'major': 1,\n",
       " 'minor': 1,\n",
       " 'manufacturers.': 1,\n",
       " 'truck': 1,\n",
       " 'local': 1,\n",
       " 'South': 1,\n",
       " 'American': 1,\n",
       " 'authorities': 1,\n",
       " 'forest?': 1,\n",
       " 'identify:': 1,\n",
       " 'official': 1,\n",
       " 'organizations,': 1,\n",
       " 'institutions,': 1,\n",
       " 'included': 1,\n",
       " 'indications': 1,\n",
       " 'degrees': 1,\n",
       " 'success': 1,\n",
       " 'endeavors.': 1,\n",
       " 'storms': 1,\n",
       " '(hurricanes': 1,\n",
       " 'typhoons)': 1,\n",
       " 'significant': 1,\n",
       " 'property': 1,\n",
       " 'life?': 1,\n",
       " 'date': 1,\n",
       " 'storm,': 1,\n",
       " 'affected,': 1,\n",
       " 'extent': 1,\n",
       " 'damage/casualties': 1,\n",
       " 'interest.': 1,\n",
       " 'storm': 1,\n",
       " '\"slight\",': 1,\n",
       " '\"limited\",': 1,\n",
       " '\"small\"': 1,\n",
       " 'much': 1,\n",
       " 'export': 1,\n",
       " 'import': 1,\n",
       " 'it?': 1,\n",
       " 'provide': 1,\n",
       " 'regarding': 1,\n",
       " \"Cuba's\": 1,\n",
       " 'trade.': 1,\n",
       " 'Sugar': 1,\n",
       " 'production': 1,\n",
       " 'statistics': 1,\n",
       " 'exports': 1,\n",
       " 'mentioned': 1,\n",
       " 'explicitly.': 1,\n",
       " 'art?': 1,\n",
       " 'Instances': 1,\n",
       " 'Stolen': 1,\n",
       " 'things,': 1,\n",
       " 'might': 1,\n",
       " 'decorative,': 1,\n",
       " '(unless': 1,\n",
       " 'reproductions).': 1,\n",
       " 'Pirated': 1,\n",
       " 'software,': 1,\n",
       " 'music,': 1,\n",
       " 'movies,': 1,\n",
       " 'Provide': 1,\n",
       " 'enforcement': 1,\n",
       " 'purposes.': 1,\n",
       " 'items': 1,\n",
       " 'operation.': 1,\n",
       " 'Training': 1,\n",
       " 'handlers': 1,\n",
       " 'ultraviolet': 1,\n",
       " '(UV)': 1,\n",
       " 'light': 1,\n",
       " 'sun': 1,\n",
       " 'do': 1,\n",
       " 'eyes.': 1,\n",
       " 'diseases': 1,\n",
       " 'eyes': 1,\n",
       " 'UV': 1,\n",
       " 'light,': 1,\n",
       " 'treatments': 1,\n",
       " 'damage,': 1,\n",
       " 'damage.': 1,\n",
       " 'cataracts': 1,\n",
       " 'ocular': 1,\n",
       " 'melanoma': 1,\n",
       " 'when': 1,\n",
       " 'mentioned.': 1,\n",
       " 'However,': 1,\n",
       " 'radiation': 1,\n",
       " 'nuclear': 1,\n",
       " 'sources': 1,\n",
       " 'lasers': 1,\n",
       " 'contemporary': 1,\n",
       " 'interest': 1,\n",
       " 'stoicism?': 1,\n",
       " 'Actual': 1,\n",
       " 'philosophers,': 1,\n",
       " 'stoic': 1,\n",
       " 'plays,': 1,\n",
       " '\"stoic\"': 1,\n",
       " 'artistic': 1,\n",
       " 'inventions': 1,\n",
       " 'made?': 1,\n",
       " 'word': 1,\n",
       " '\"new\"': 1,\n",
       " 'defined': 1,\n",
       " '1990s.': 1,\n",
       " '\"recent\"': 1,\n",
       " 'invention': 1,\n",
       " 'discovery': 1,\n",
       " 'considered': 1,\n",
       " 'Discoveries': 1,\n",
       " 'made': 1,\n",
       " 'astronomy': 1,\n",
       " 'patentable': 1,\n",
       " 'accounts': 1,\n",
       " 'selfless': 1,\n",
       " 'small': 1,\n",
       " 'benefit': 1,\n",
       " 'cause.': 1,\n",
       " 'acts.': 1,\n",
       " 'General': 1,\n",
       " 'concerning': 1,\n",
       " 'besides': 1,\n",
       " 'United': 1,\n",
       " 'States': 1,\n",
       " 'approved': 1,\n",
       " 'persons?': 1,\n",
       " 'woman': 1,\n",
       " 'installed': 1,\n",
       " 'installation.': 1,\n",
       " 'position': 1,\n",
       " 'pastor': 1,\n",
       " 'rather': 1,\n",
       " 'than': 1,\n",
       " 'capacity': 1,\n",
       " '(e.g.,': 1,\n",
       " 'nun': 1,\n",
       " 'choir': 1,\n",
       " 'member).': 1,\n",
       " 'resulted': 1,\n",
       " 'deaths.': 1,\n",
       " 'killed': 1,\n",
       " 'animal': 1,\n",
       " 'could': 1,\n",
       " 'public': 1,\n",
       " 'place': 1,\n",
       " 'sporting': 1,\n",
       " 'event,': 1,\n",
       " 'bar,': 1,\n",
       " 'restaurant': 1,\n",
       " 'entertainment': 1,\n",
       " 'event.': 1,\n",
       " 'number': 1,\n",
       " 'receiving': 1,\n",
       " 'benefits.': 1,\n",
       " 'changes': 1,\n",
       " 'allowing': 1,\n",
       " 'recipients': 1,\n",
       " 'imply': 1,\n",
       " 'people,': 1,\n",
       " 'immigrants,': 1,\n",
       " 'stamps': 1,\n",
       " 'hiring': 1,\n",
       " 'potential': 1,\n",
       " 'income': 1,\n",
       " 'graduates': 1,\n",
       " 'colleges.': 1,\n",
       " 'cite': 1,\n",
       " 'college': 1,\n",
       " 'job': 1,\n",
       " 'opportunities.': 1,\n",
       " 'citing': 1,\n",
       " 'opportunities': 1,\n",
       " 'non-college': 1,\n",
       " 'vocational-training': 1,\n",
       " 'Africa.': 1,\n",
       " 'Religious': 1,\n",
       " 'beliefs': 1,\n",
       " 'Africa': 1,\n",
       " 'hinder': 1,\n",
       " 'stop': 1,\n",
       " 'there.': 1,\n",
       " 'principles': 1,\n",
       " 'vaccinations.': 1,\n",
       " 'expressions': 1,\n",
       " 'changing': 1,\n",
       " 'allow': 1,\n",
       " 'drive.': 1,\n",
       " 'protests': 1,\n",
       " 'against': 1,\n",
       " 'current': 1,\n",
       " 'driving': 1,\n",
       " 'lifting': 1,\n",
       " 'leaders': 1,\n",
       " 'spokespeople,': 1,\n",
       " 'domestically': 1,\n",
       " 'internationally.': 1,\n",
       " 'Articles': 1,\n",
       " 'note': 1,\n",
       " 'existence': 1,\n",
       " 'only': 1,\n",
       " 'historical,': 1,\n",
       " 'keeping': 1,\n",
       " 'economic': 1,\n",
       " 'decisions': 1,\n",
       " 'negative': 1,\n",
       " 'effect': 1,\n",
       " 'employment.': 1,\n",
       " 'select': 1,\n",
       " 'replace': 1,\n",
       " 'pro': 1,\n",
       " 'con': 1,\n",
       " 'idea': 1,\n",
       " 'appearing': 1,\n",
       " 'Discussion': 1,\n",
       " 'irony': 1,\n",
       " 'replacing': 1,\n",
       " 'Would': 1,\n",
       " 'viable': 1,\n",
       " 'method': 1,\n",
       " 'controlling/eradicating': 1,\n",
       " 'them?': 1,\n",
       " 'eaten': 1,\n",
       " 'beings': 1,\n",
       " 'likelihood': 1,\n",
       " 'through': 1,\n",
       " 'consumption.': 1,\n",
       " 'Comments': 1,\n",
       " 'color,': 1,\n",
       " 'taste,': 1,\n",
       " 'texture,': 1,\n",
       " 'culinary': 1,\n",
       " 'qualities': 1,\n",
       " 'people?': 1,\n",
       " 'paralyzed,': 1,\n",
       " 'currently': 1,\n",
       " 'under': 1,\n",
       " 'development.': 1,\n",
       " 'move': 1,\n",
       " 'uses': 1,\n",
       " 'Tests': 1,\n",
       " 'studies': 1,\n",
       " 'animals': 1,\n",
       " \"don't\": 1,\n",
       " 'show': 1,\n",
       " 'persons': 1,\n",
       " 'disabilities': 1,\n",
       " 'malady': 1,\n",
       " 'prompted': 1,\n",
       " 'seek': 1,\n",
       " 'itself.': 1,\n",
       " 'published': 1,\n",
       " 'after': 1,\n",
       " 'death': 1,\n",
       " 'he': 1,\n",
       " 'suspects.': 1,\n",
       " 'sentences': 1,\n",
       " 'received.': 1,\n",
       " 'underway': 1,\n",
       " 'Earth': 1,\n",
       " 'strikes?': 1,\n",
       " 'real-life': 1,\n",
       " 'earth': 1,\n",
       " 'strike.': 1,\n",
       " 'Information': 1,\n",
       " 'detecting': 1,\n",
       " 'tracking': 1,\n",
       " 'asteroids': 1,\n",
       " 'defense.': 1,\n",
       " 'diabetes?': 1,\n",
       " 'diabetes,': 1,\n",
       " 'deny': 1,\n",
       " 'link.': 1,\n",
       " 'vulnerable': 1,\n",
       " 'hacked,': 1,\n",
       " 'tools,': 1,\n",
       " 'standards': 1,\n",
       " 'policies': 1,\n",
       " 'deter': 1,\n",
       " 'hacking.': 1,\n",
       " 'digital': 1,\n",
       " 'hacked.': 1,\n",
       " 'report': 1,\n",
       " 'automakers,': 1,\n",
       " 'developers,': 1,\n",
       " 'legislative': 1,\n",
       " 'bodies': 1,\n",
       " 'proactively': 1,\n",
       " 'detect': 1,\n",
       " 'hacking': 1,\n",
       " 'detailing': 1,\n",
       " 'bully': 1,\n",
       " 'teenager': 1,\n",
       " 'ultimately': 1,\n",
       " 'led': 1,\n",
       " \"teen's\": 1,\n",
       " 'suicide.': 1,\n",
       " 'give': 1,\n",
       " 'teen': 1,\n",
       " 'committed': 1,\n",
       " 'suicide': 1,\n",
       " 'target': 1,\n",
       " 'form': 1,\n",
       " 'media.': 1,\n",
       " 'includes': 1,\n",
       " 'source': 1,\n",
       " 'consequences': 1,\n",
       " 'faced': 1,\n",
       " 'bully.': 1,\n",
       " 'differences': 1,\n",
       " 'potency': 1,\n",
       " 'generation': 1,\n",
       " 'compares': 1,\n",
       " 'highlights': 1,\n",
       " 'difference': 1,\n",
       " 'THC,': 1,\n",
       " 'psychoactive': 1,\n",
       " 'ingredient': 1,\n",
       " 'potency,': 1,\n",
       " 'generally': 1,\n",
       " 'available': 1,\n",
       " '30': 1,\n",
       " 'years': 1,\n",
       " 'long-term': 1,\n",
       " 'policy?': 1,\n",
       " 'policy': 1,\n",
       " 'economy': 1,\n",
       " 'structure.': 1,\n",
       " 'release': 1,\n",
       " 'served': 1,\n",
       " 'prison': 1,\n",
       " 'released,': 1,\n",
       " 'released.': 1,\n",
       " 'wage.': 1,\n",
       " 'advocacy': 1,\n",
       " '(or': 1,\n",
       " 'thereof)': 1,\n",
       " 'wage,': 1,\n",
       " 'including': 1,\n",
       " 'increases': 1,\n",
       " 'government': 1,\n",
       " 'contract': 1,\n",
       " 'workers.': 1,\n",
       " 'Analyses': 1,\n",
       " 'discussions': 1,\n",
       " 'pros': 1,\n",
       " 'cons': 1,\n",
       " 'talking': 1,\n",
       " 'heads': 1,\n",
       " 'Gross': 1,\n",
       " 'Cuban': 1,\n",
       " 'Gross,': 1,\n",
       " 'imprisoned': 1,\n",
       " 'five': 1,\n",
       " 'years,': 1,\n",
       " 'release,': 1,\n",
       " 'simply': 1,\n",
       " 'observations': 1,\n",
       " 'imprisonment.': 1,\n",
       " 'diet.': 1,\n",
       " 'okay': 1,\n",
       " \"one's\": 1,\n",
       " 'diet,': 1,\n",
       " 'recommends': 1,\n",
       " 'nutritional': 1,\n",
       " 'value.': 1,\n",
       " 'demographics': 1,\n",
       " 'U.S.:': 1,\n",
       " 'per': 1,\n",
       " 'total': 1,\n",
       " 'demographic': 1,\n",
       " 'data': 1,\n",
       " 'each': 1,\n",
       " 'comprises': 1,\n",
       " 'overall': 1,\n",
       " 'rate': 1,\n",
       " 'infection.': 1,\n",
       " 'rates': 1,\n",
       " 'serious': 1,\n",
       " 'viral': 1,\n",
       " 'scams': 1,\n",
       " 'defrauded': 1,\n",
       " 'money': 1,\n",
       " 'assets.': 1,\n",
       " 'instance': 1,\n",
       " 'someone': 1,\n",
       " 'suffered': 1,\n",
       " 'scam,': 1,\n",
       " 'sufficient': 1,\n",
       " 'provided': 1,\n",
       " 'scam': 1,\n",
       " 'used.': 1,\n",
       " 'Generic': 1,\n",
       " 'assumed': 1,\n",
       " 'behind': 1,\n",
       " 'hack': 1,\n",
       " 'bacteria.': 1,\n",
       " 'precautionary': 1,\n",
       " 'existing': 1,\n",
       " \"Bezos'\": 1,\n",
       " 'paper.': 1,\n",
       " 'Bezos.': 1,\n",
       " 'Statements': 1,\n",
       " 'Graham': 1,\n",
       " 'family': 1,\n",
       " 'sale': 1,\n",
       " 'Does': 1,\n",
       " 'diversion': 1,\n",
       " 'crops': 1,\n",
       " 'into': 1,\n",
       " 'prices?': 1,\n",
       " 'growing': 1,\n",
       " 'intention': 1,\n",
       " 'prices': 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_description = set(a['description'][0].split(\" \"))\n",
    "terms_narrative = set(a['narrative'][0].split(\" \"))\n",
    "terms_narrative.union(terms_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_narrative.union(terms_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate user for sim config\n",
    "\n",
    "user_xmls = sorted(glob.glob(\"/workspace/sims/users/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user configurationFile=\"/workspace/sims/users/gpt+_snipsummarytf2_10rpp_wapo.xml\"/>\n",
      "<user configurationFile=\"/workspace/sims/users/gpt+_snipsummarytf3_10rpp_wapo.xml\"/>\n",
      "<user configurationFile=\"/workspace/sims/users/gpt+_snipsummarytf4_10rpp_wapo.xml\"/>\n",
      "<user configurationFile=\"/workspace/sims/users/gpt+_snipsummarytf5_10rpp_wapo.xml\"/>\n",
      "<user configurationFile=\"/workspace/sims/users/gpt+_snipsummarytf6_10rpp_wapo.xml\"/>\n"
     ]
    }
   ],
   "source": [
    "for user_xml in user_xmls:\n",
    "    if 'wapo' in user_xml and 'snip' in user_xml:\n",
    "        print(f\"<user configurationFile=\\\"{user_xml}\\\"/>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate gpt* queries (query variation only over the last term)\n",
    "\n",
    "gpt_p_lines = open(\"/workspace/data/nyt/gpt+.txt\", \"r\").read().split(\"\\n\")\n",
    "gpt_p = [line.split(\",\")[-1] for line in gpt_p_lines]\n",
    "\n",
    "gpt_p_terms = set(\" \".join(gpt_p).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace.simiir.query_generators.utils import IdfProvider, get_stopwords, filter_keywords\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_provider = IdfProvider(index_path=\"/app/indices/nyt/data.properties\", stopwords=get_stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt_canidate_terms(t_id, gpt_p_lines, idf_provider):\n",
    "    t_id_terms = []\n",
    "\n",
    "    for line in gpt_p_lines:\n",
    "        parts = line.split(\",\")\n",
    "        if parts[2] == t_id:\n",
    "            t_id_terms += parts[3].split(\" \")\n",
    "\n",
    "    t_id_terms = list(set(filter_keywords(idf_provider, t_id_terms)))\n",
    "\n",
    "    random.shuffle(t_id_terms)\n",
    "    \n",
    "    return t_id_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_gpt_canidate_terms(\"321\", gpt_p_lines, idf_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_queries = open(\"workspace/data/nyt/title_queries\", \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_s_queries = \"\"\n",
    "\n",
    "for query in seed_queries:\n",
    "    gpt_s_queries += query + \"\\n\"\n",
    "    parts = query.split(\",\")\n",
    "    candidate_terms = generate_gpt_canidate_terms(parts[2], gpt_p_lines, idf_provider)\n",
    "    for i in range(2,101):\n",
    "        if i >= len(candidate_terms):\n",
    "            r_index = random.randrange(0, len(candidate_terms))\n",
    "            line = f\"{i},1,{parts[2]},{parts[-1]} {candidate_terms[r_index]}\\n\"\n",
    "        else:\n",
    "            line = f\"{i},1,{parts[2]},{parts[-1]} {candidate_terms[i-2]}\\n\"\n",
    "        gpt_s_queries += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"workspace/data/nyt/gpt*.txt\", \"w\") as f:\n",
    "    f.write(gpt_s_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
